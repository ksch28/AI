{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0aab3e",
   "metadata": {},
   "source": [
    "# 8. 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29601eba",
   "metadata": {},
   "source": [
    "<span style='background-color:#fff5b1'>딥러닝은 층을 깊게 한 심층 신경망이다.</span><br/>\n",
    "심층 신경망은 지금까지 설명한 신경망을 바탕으로 뒷단에 층을 추가하기만 하면 만들 수 있지만, 커다란 문제가 몇 개 있다.<br/>\n",
    "이번 장에서는 <span style='background-color:#ffdce0'>딥러닝의 특징과 과제, 그리고 가능성</span>을 살펴볼것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa0bf89",
   "metadata": {},
   "source": [
    "## 8.1 더 깊게"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fcd0fe",
   "metadata": {},
   "source": [
    "신경망에 관해 그동안 많은 것을 배웠다.<br/>\n",
    "신경망을 구성하는 <span style='background-color:#ffdce0'>다양한 계층</span>과 <span style='background-color:#ffdce0'>학습에 효과적인 기술</span>, <span style='background-color:#ffdce0'>영상 분야에 특히 유효한 CNN</span>과 <span style='background-color:#ffdce0'>매개변수 최적화 기법</span> 등이 떠오를 것이다.<br/>\n",
    "이 모두가 딥러닝에서 중요한 기술이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87e17f",
   "metadata": {},
   "source": [
    "### 8.1.1 더 깊은 신경망으로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ee375",
   "metadata": {},
   "source": [
    "이번 장에서는 다음 그림과 같이 구성된 CNN을 만들고자 한다.<br/>\n",
    "<img src=\"https://velog.velcdn.com/post-images%2Fdscwinterstudy%2Fbb9c3a30-4192-11ea-82e0-f10b8886fb3a%2F%EC%86%90%EA%B8%80%EC%94%A8%EC%8B%AC%EC%B8%B5CNN.png\" align=\"left\" height=500 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed5c9b",
   "metadata": {},
   "source": [
    "훑어보기만해도 지금까지 구현한 신경망보다 층이 깊다.<br/>\n",
    "여기에서 사용하는 합성곱 계층은 모두 3$\\times$3 크기의 작은 필터로, <span style='background-color:#ffdce0'>층이 깊어지면서 채널 수가 더 늘어나는 것이 특징이다.</span><br/>\n",
    "또 그림과 같이 <span style='background-color:#ffdce0'>풀링 계층을 추가하여 중간 데이터의 공간 크기를 점차 줄여간다.</span><br/>\n",
    "그리고 마지막 단의 완전연결 계층에서는 <span style='background-color:#ffdce0'>드롭아웃 계층</span>을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c94f25",
   "metadata": {},
   "source": [
    "가중치 초깃값으로 <span style='background-color:#ffdce0'>He 초깃값</span>을 사용하고, 가중치 매개변수 갱신에는 <span style='background-color:#ffdce0'>Adam</span>을 이용한다.<br/>\n",
    "이상을 정리하면 이 신경망의 특징은 다음과 같다.\n",
    "1. 3$\\times$3의 작은 필터를 사용한 합성곱 계층\n",
    "2. 활성화 함수는 ReLU\n",
    "3. 완전연결 계층 뒤에 Dropout 계층 사용\n",
    "4. Adam을 사용해 최적화\n",
    "5. 가중치 초깃값은 He 초깃값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9116e824",
   "metadata": {},
   "source": [
    "이상의 특징에서 보듯 이 신경망에는 그동안 배운 기술을 잔뜩 녹여냈다.<br/>\n",
    "이 신경망을 학습시키면 정확도가 매우 높게 나온다.(약 99%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd72da",
   "metadata": {},
   "source": [
    "### 8.1.2 정확도를 더 높이려면"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a41feb",
   "metadata": {},
   "source": [
    "<span style='background-color:#fff5b1'>데이터 확장(Data Augmentation)은 손쉬운 방법이면서도 정확도 개선에 아주 효과적이다.</span><br/>\n",
    "데이터 확장은 입력 이미지(훈련 이미지)를 알고리즘을 동원하여 <span style='background-color:#ffdce0'>인위적으로</span> 확장한다.(입력 이미지를 회전하거나 세로로 이동하는 등 미세한 변화를 준다.)<br/>\n",
    "이는 데이터가 몇 개 없을 때 특히 효과적인 수단이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee38841",
   "metadata": {},
   "source": [
    "데이터 확장은 회전이나 이동에 의한 변형 외에도 <span style='background-color:#ffdce0'>crop(이미지 일부를 잘라냄)</span>이나 <span style='background-color:#ffdce0'>flip(좌우를 뒤집음)</span>을 이용하여 다양한 방법으로 이미지를 확장할 수 있다.<br/>\n",
    "일반적인 이미지에는 밝기 등의 외형 변화나 <span style='background-color:#ffdce0'>확대$\\cdot$축소 등의 스케일 변화에도 효과적</span>이다.<br/>\n",
    "어쨌든 데이터 확장을 동원해 훈련 이미지의 개수를 늘릴 수 있다면 딥러닝의 인식 수준을 개선할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e552de5d",
   "metadata": {},
   "source": [
    "### 8.1.3 층을 깊게 하는 이유"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229d4f8",
   "metadata": {},
   "source": [
    "층을 깊게 하는 것의 중요성은 ILSVRC로 대표되는 대규모 이미지 인식 대회의 결과에서 파악할 수 있다.<br/>\n",
    "이 대회에서 최근 상위를 차지한 기법 대부분은 딥러닝 기반이며, 그 경향은 신경망을 더 깊게 만드는 방향으로 가고 있다.<br/>\n",
    "<span style='background-color:#ffdce0'>층의 깊이에 비례해 정확도가 좋아지는 것</span>이다.<br/>\n",
    "층을 깊게 할 때의 이점은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b85830",
   "metadata": {},
   "source": [
    "#### 1. 신경망의 매개변수 수가 줄어든다.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040df90",
   "metadata": {},
   "source": [
    "<span style='background-color:#ffdce0'>층을 깊게 한 신경망은 깊지 않은 경우보다 적은 매개변수로 같은(혹은 그 이상) 수준의 표현력을 달성할 수 있다.</span><br/>\n",
    "합성곱 연산에서의 <span style='background-color:#ffdce0'>필터 크기에 주목</span>해 생각해보면 쉽게 이해할 수 있다.<br/>\n",
    "다음 그림은 5$\\times$5 필터로 구성된 합성곱 계층이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9d58f",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F9Ek4E%2FbtqKqyMce4n%2F9Dy3SozQKZulfyNR4hALk0%2Fimg.png\" align=\"left\" height=500 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20419a4e",
   "metadata": {},
   "source": [
    "여기에서 주목할 점은 출력 데이터의 각 노드가 입력 데이터의 어느 영역으로부터 게산되었느냐는 것이다.<br/>\n",
    "당연하지만 위 그림의 예시에서는 각각의 출력 노드는 입력 데이터의 5$\\times$5 크기 영역에서 계산된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b613d261",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbtXZXB%2FbtqKrLjZS2l%2F2LCxl0df3RKyoBjqU66kU0%2Fimg.png\" align=\"left\" height=500 width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cbe247",
   "metadata": {},
   "source": [
    "이어서 위 그림처럼 3$\\times$3의 합성곱 연산을 2회 반복하는 경우를 살펴보자.<br/>\n",
    "이 경우 출력 노드 하나는 중간 데이터의 3$\\times$3 영역에서 계산된다.<br/>\n",
    "그럼 중간 데이터의 3$\\times$3 영역은 그전 입력 데이터의 어느 영역에서 계산될까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a51cba8",
   "metadata": {},
   "source": [
    "위 그림을 잘 보면 5$\\times$5 크기의 영역에서 계산되어 나오는 것을 알 수 있다.<br/>\n",
    "즉, 위 그림의 출력 데이터는 입력 데이터의 5$\\times$5 영역을 보고 계산하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1efbde8",
   "metadata": {},
   "source": [
    "<span style='background-color:#ffdce0'>5$\\times$5 의 합성곱 연산 1회는 3$\\times$3의 합성곱 연산을 2회 수행하여 대체할 수 있다.</span><br/>\n",
    "게다가 <span style='background-color:#ffdce0'>전자의 매개변수가 25개(5$\\times$5)</span>인 반면, <span style='background-color:#ffdce0'>후자는 총 18회(2$\\times$3$\\times$3)</span>이며, 매개변수는 층을 반복할수록 적어진다. 그리고 <span style='background-color:#ffdce0'>그 개수의 차이는 층이 깊어질수록 커진다.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999caa88",
   "metadata": {},
   "source": [
    "예를 들어 <span style='background-color:#fff5b1'>3$\\times$3의 합성곱 연산을 3회 반복하면 매개변수는 모두 27개</span>가 되지만, <span style='background-color:#fff5b1'>같은 크기의 영역을 1회의 합성곱 연산으로 보기 위해서는 7$\\times$7의 필터,<br/> 즉 매개변수 49개가 필요하다.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2304d5d",
   "metadata": {},
   "source": [
    "####  2. 학습의 효율성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9239f7",
   "metadata": {},
   "source": [
    "학습의 효율성도 층을 깊게 하는 것의 이점이다.<br/>\n",
    "<span style='background-color:#fff5b1'>층을 깊게 함으로써 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다는 뜻이다.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e428fbb0",
   "metadata": {},
   "source": [
    "[7.6절의 CNN 시각화하기](https://github.com/ksch28/DeepLearning_for_scratch/blob/main/Ch_7_2nd.ipynb)에서 CNN의 합성곱 계층이 <span style='background-color:#fff5b1'>정보를 계층적으로 추출하고 있음</span>을 설명했다.<br/>\n",
    "앞단의 합성곱 계층에서는 에지와 블롭같은 단순한 패턴에 뉴런이 반응하고 층이 깊어지면서 텍스쳐와 사물의 일부와 같이 점차 더 복잡한 것에 반응한다고 설명했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a804f2",
   "metadata": {},
   "source": [
    "#### 3. 정보를 계층적으로 전달할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b0c1d",
   "metadata": {},
   "source": [
    "<span style='background-color:#fff5b1'>층을 깊게 하면 정보를 계층적으로 전달할 수 있다는 점도 중요하다.</span><br/>\n",
    "예를 들어, 에지를 추출한 층의 다음 층은 에지 정보를 쓸 수 있고, 더 고도의 패턴을 효과적으로 학습하리라 기대할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63935bf2",
   "metadata": {},
   "source": [
    "즉, 층을 깊이 함으로써 각 층이 학습해야 할 문제를 <span style='background-color:#ffdce0'>풀기 쉬운 단순한 문제로 분해</span>할 수 있어 효율적으로 학습하리라 기대할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8333305",
   "metadata": {},
   "source": [
    "## 8.2 여러가지 신경망 - VGG, GoogLeNet, ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67284d57",
   "metadata": {},
   "source": [
    "### 8.2.1 VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0c48e",
   "metadata": {},
   "source": [
    "VGG는 <span style='background-color:#fff5b1'>합성곱 계층과 풀링 계층으로 구성되는 기본적인 CNN이다.</span><br/>\n",
    "다만, 그림과 같이 비중 있는 층(합성곱 계층, 완전연결 계층)을 모두 16층(총 19층)으로 <span style='background-color:#fff5b1'>심화</span>한 것이 특징이다.<br/>\n",
    "(층의 깊이에 따라서 'VGG16', 'VGG19'로 구분하기도 한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e2ba5",
   "metadata": {},
   "source": [
    "<img src=\"https://velog.velcdn.com/post-images%2Fdscwinterstudy%2Fea967bb0-4193-11ea-82e0-f10b8886fb3a%2FVGG.png\" align=\"left\" height=500 width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ed890",
   "metadata": {},
   "source": [
    "VGG에서 주목할 점은 <span style='background-color:#fff5b1'>3$\\times$3의 작은 필터를 사용한 합성곱 계층을 연속으로 거친다는 것이다.</span><br/>\n",
    "그림에서 보듯 합성곱 계층을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리를 반복한다.<br/>\n",
    "그리고 마지막에는 <span style='background-color:#fff5b1'>완전연결 계층을 통과하여 결과를 출력</span>한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deaf222",
   "metadata": {},
   "source": [
    "### 8.2.2 GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c661f",
   "metadata": {},
   "source": [
    "GoogLeNet의 구성은 아래 그림과 같다.<br/>\n",
    "기본적으로 기존의 CNN과 크게 다르지 않지만 GoogLeNet은 <span style='background-color:#fff5b1'>세로 방향 깊이뿐만 아니라 가로 방향도 깊다는 점이 특징</span>이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df7bb9",
   "metadata": {},
   "source": [
    "GoogLeNet에는 가로방향에 <span style='background-color:#fff5b1'>폭</span>이 있다. 이를 <span style='background-color:#fff5b1'>인셉션 구조</span>라 하며 그 기반 구조는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0afbe3",
   "metadata": {},
   "source": [
    "<img src=\"https://velog.velcdn.com/post-images%2Fdscwinterstudy%2F8556b550-419b-11ea-a3b8-fd5b14e3378a%2F%EA%B5%AC%EA%B8%80%EB%84%B7%EC%9D%B8%EC%85%89%EC%85%98.png\" align=\"left\" height=500 width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5237012",
   "metadata": {},
   "source": [
    "인셉션 구조는 그림과 같이 <span style='background-color:#fff5b1'>크기가 다른 필터와 풀링을 여러개 적용하여 그 결과를 결합</span>한다.<br/>\n",
    "이 인셉션 구조를 하나의 빌딩 블록(구성요소)으로 사용하는 것이 GoogLeNet의 특징인 것이다.<br/>\n",
    "또, GoogLeNet에서는 1$\\times$1의 합성곱 연산은 채널쪽으로 크기를 줄이는 것으로, 매개변수 제거와 고속 처리에 기여한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae900816",
   "metadata": {},
   "source": [
    "### 8.2.3 ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee72f5",
   "metadata": {},
   "source": [
    "ResNet(Residual Network)은 마이크로소프트의 팀이 개발한 네트워크이다.<br/>\n",
    "그 특징은 지금까지보다 층을 더 깊게 할 수 있는 특별한 <span style='background-color:#fff5b1'>장치</span>에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71939e38",
   "metadata": {},
   "source": [
    "지금까지 층을 깊게 하는 것이 성능 향상에 중요하다는 것은 알고 있었다.<br/>\n",
    "<span style='background-color:#ffdce0'>그러나 딥러닝 학습에서는 층이 지나치게 깊으면 학습이 잘 되지 않고 오히려 성능이 떨어지는 경우도 많다.</span><br/>\n",
    "ResNet에서는 그런 문제를 해결하기 위해서 <span style='background-color:#fff5b1'>스킵 연결(skip connection)</span>을 도입한다.<br/>\n",
    "이 구조가 층의 깊이에 비례해 성능을 향상시킬 수 있게 한 핵심이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee219794",
   "metadata": {},
   "source": [
    "<span style='background-color:#fff5b1'>스킵 연결이란 아래 그림과 같이 입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조</span>를 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ea454",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FXFGLw%2FbtqKy6uEvdc%2FzkY43cvgvuFmiGBVZ05ir0%2Fimg.png\" align=\"left\" height=200 width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ccf17a",
   "metadata": {},
   "source": [
    "위 그림에서는 입력 $x$를 연속한 두 합성곱 계층을 건너뛰어 출력에 바로 연결한다.<br/>\n",
    "이 단축 경로가 없었다면 두 합성곱 계층의 출력이 <span style='background-color:#fff5b1'>$F(x)$</span>가 되나, 스킵 연결로 인해 <span style='background-color:#fff5b1'>$F(x) + x$</span>가 되는게 핵심이다.<br/>\n",
    "스킵 연결은 층이 깊어져도 학습을 <span style='background-color:#fff5b1'>효율적</span>으로 할 수 있도록 해주는데, 이는 역전파 때 스킵 연결이 <span style='background-color:#fff5b1'>신호 감쇠를 막아주기 때문</span>이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e1404f",
   "metadata": {},
   "source": [
    "ResNet은 먼저 설명한 VGG 신경망을 기반으로 스킵 연결을 도입하여 층을 깊게 했다.<br/>\n",
    "그 결과는 아래 그림처럼 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9354b599",
   "metadata": {},
   "source": [
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcx4XFl%2FbtqKuHchZQo%2FtXgvrGZvIvm1KPByS47x80%2Fimg.png\" align=\"left\" height=500 width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc559eee",
   "metadata": {},
   "source": [
    "그림과 같이 ResNet은 합성곱 계층을 2개 층마다 건너뛰면서 층을 깊게 한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
