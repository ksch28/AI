{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c221152b",
   "metadata": {},
   "source": [
    "# 5. 오차역전파법(역전파)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4235040",
   "metadata": {},
   "source": [
    "* 앞 장에서는 신경망 학습을 할 때 가중치 매개변수에 대한 손실 함수의 기울기는 수치 미분을 사용해 구했다.\n",
    "* 수치 미분은 단순하고 구현하기도 쉽지만, 계산 시간이 오래 걸린다는 단점이 있다.\n",
    "* 이번 장에서는 가중치 매개변수의 기울기를 효율적으로 계산하는 <span style='color:blue'>오차역전파법(backpropagation)</span>을 배워보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b9ce2e",
   "metadata": {},
   "source": [
    "## 5.4 단순한 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d076076",
   "metadata": {},
   "source": [
    "* 계산그래프의 곱셈 노드를 'MulLayer' 덧셈 노드를 'AddLayer'라는 이름으로 구현해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51310e6f",
   "metadata": {},
   "source": [
    "### 5.4.1 곱셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8f8eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003 \n",
      " ------------------------------\n",
      "2.2 110.00000000000001 200\n"
     ]
    }
   ],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x*y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        dy = dout * self.x\n",
    "        \n",
    "        return dx, dy\n",
    "    \n",
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print(price, '\\n', '-'*30)\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "print(dapple, dapple_num, dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b9e98",
   "metadata": {},
   "source": [
    "### 5.4.2 덧셈 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e6064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        \n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d580706",
   "metadata": {},
   "source": [
    "* 덧셈 계층과 곱셈 계층을 사용하여 사과 2개와 귤 3개를 사는 상황을 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd17c45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "2.2 | 110.00000000000001 | 3.3000000000000003 | 165.0 | 650\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)\n",
    "price = mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple_price,  dorange_price = add_apple_orange_layer.backward(dall_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "\n",
    "print(price)\n",
    "print(dapple,'|',dapple_num,'|',dorange,'|',dorange_num,'|',dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7337e2d",
   "metadata": {},
   "source": [
    "## 5.5 활성화 함수 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9368fdc",
   "metadata": {},
   "source": [
    "* ReLU와 Sigmoid 계층을 구현해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6924bd",
   "metadata": {},
   "source": [
    "### 5.5.1 ReLU 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a400d0",
   "metadata": {},
   "source": [
    "### $y = \\begin{cases}x & {(x > 0)} \\\\ 0 & {(x \\le 0)}\\end{cases}$<br/>\n",
    "* 위 식에 대한 미분은 아래와 같다.<br/>\n",
    "### ${\\partial{y}\\over\\partial{x}} = {\\begin{cases}1 & {(x > 0)} \\\\ 0 & {(x \\le 0)}\\end{cases}}$<br/>\n",
    "* 계산그래프로는 아래와 같다.<br/>\n",
    "<img src=\"https://velog.velcdn.com/images%2Fkimkihoon0515%2Fpost%2Ff094bb3f-c425-4390-b715-be429399b5a4%2Fimage.png\" align=\"left\" height=\"800px\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10b1a4",
   "metadata": {},
   "source": [
    "* 이제 ReLU 계층을 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abbf3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]] \n",
      " --------------------\n",
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx\n",
    "    \n",
    "x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n",
    "print(x, '\\n', '-'*20)\n",
    "\n",
    "mask = (x <= 0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a00853",
   "metadata": {},
   "source": [
    "* ReLU 클래스는 mask라는 인스턴스 변수를 가진다.\n",
    "* mask는 True/False로 구성된 넘파이 배열로, 순전파의 입력인 x의 원소값이 0 이하인 인덱스는 True로, 그 외는 False로 유지한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ec0756",
   "metadata": {},
   "source": [
    "### 5.5.2 Sigmoid 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd245f",
   "metadata": {},
   "source": [
    "* 수식으로는 아래와 같다.<br/>\n",
    "## $y = {1 \\over {1 + e^{-x}}}$ <br/>\n",
    "* 계산 그래프는 아래와 같다.<br/>\n",
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2F8aef041f-e1b3-4077-aa1a-a1e24054ad43%2Fimage.png\" align=\"left\" height=\"500px\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7dfc07",
   "metadata": {},
   "source": [
    "* sigmoid 함수의 역전파를 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1e044",
   "metadata": {},
   "source": [
    "#### <span style='background-color:yellow'>1단계</span><br/>\n",
    "* '/' 노드, 즉 $y={1 \\over x}$을 미분하면 다음과 같다.<br/>\n",
    "## ${\\partial y \\over \\partial x} = {-{1 \\over x^2}} = {-y^2}$ <br/>\n",
    "* 위 식에 따르면 역전파 때는 상류에서 하류로 들어온 값에 $-y^2$(순전파의 출력을 제곱한 후 마이너스)을 곱해서 하류로 전달한다. 계산 그래프로는 아래와 같다.<br/>\n",
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2F866b47c6-155f-4a89-a3c3-73373744b5a9%2Fimage.png\" align=\"left\" height=\"500px\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801349a",
   "metadata": {},
   "source": [
    "#### <span style='background-color:yellow'>2단계</span><br/>\n",
    "* '+' 노드는 상류의 값을 여과없이 하류로 내보낸다. 계산 그래프에서는 다음과 같다.<br/>\n",
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2F34ef6e35-e205-4015-9de8-087cad876c38%2Fimage.png\" align=\"left\" height=\"500px\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963fa14",
   "metadata": {},
   "source": [
    "#### <span style='background-color:yellow'>3단계</span><br/>\n",
    "* 'exp' 노드는 $y = e^x$ 연산을 수행하며, 그 미분은 다음과 같다.<br/>\n",
    "## ${\\partial{y}\\over\\partial{x}} = {e^x}$<br/>\n",
    "* 계산 그래프에서는 상류의 값에 순전파 때의 출력을 곱해 하류로 전파한다.<br/>\n",
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2F34d261f3-fa57-4fa4-b37c-d3efdf91a41c%2Fimage.png\" align=\"left\" height=\"500px\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e18efec",
   "metadata": {},
   "source": [
    "#### <span style='background-color:yellow'>4단계</span><br/>\n",
    "* 'x' 노드는 순전파 때의 값을 <span style='color:blue'>서로 바꿔</span> 곱한다.<br/>\n",
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2Fe4fc1d53-2443-477e-a9b0-3e5a9fae8eb3%2Fimage.png\" align=\"left\" height=\"500px\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a0106",
   "metadata": {},
   "source": [
    "* 이상으로 Sigmoid 계층의 역전파를 계산 그래프로 완성하였다.\n",
    "* 위 그림에서 보듯이 역전파의 최종 출력인 ${\\partial{L}\\over\\partial{y}}{y^2}{e^{-x}}$ 값이 하류 노트로 전파된다.\n",
    "* 여기서 위 식은 순전파의 입력 $x$와 출력 $y$ 만으로 계산할 수 있으므로, 계산 그래프의 중간과정을 모두 묶어 단순한 'sigmoid' 노드 하나로 대체할 수 있다.\n",
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2F2b877b61-b267-4852-9022-a9da55c1db00%2Fimage.png\" align=\"left\" height=\"300px\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a4219",
   "metadata": {},
   "source": [
    "* 또한, ${\\partial{L}\\over\\partial{y}}{y^2}{e^{-x}}$ 는 다음처럼 정리해서 쓸 수 있다.<br/>\n",
    "## ${\\partial{L}\\over\\partial{y}}{y^2}{e^{-x}}$ = ${\\partial{L}\\over\\partial{y}}{1\\over{(1 + e^{-x})^2}}e^{-x}$ = ${\\partial{L}\\over\\partial{y}}{1\\over{1 + e^{-x}}}{e^{-x}\\over{1 + e^{-x}}}$ = ${\\partial{L}\\over\\partial{y}}{y(1-y)}$<br/>\n",
    "* 이처럼 Sigmoid 계층의 역전파는 순전파의 출력$(y)$만으로 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb10d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.out * (1 - self.out)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954773e",
   "metadata": {},
   "source": [
    "## 5.6 Affine/Softmax 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5365de",
   "metadata": {},
   "source": [
    "### 5.6.1 Affine 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9960cd8",
   "metadata": {},
   "source": [
    "* 신경망의 순전파에서는 가중치 신호의 총합을 계산하기위해 행렬의 곱을 사용.\n",
    "* 신경망의 순전파 때 수행하는 행렬의 곱을 기하학에서는 <span style=\"color:blue\">Affine 변환</span>이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e7930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) (2, 3) (3,) \n",
      " ------------------------------\n",
      "[-4.31328586 -1.59568786  4.18814084] (3,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.randn(2,)\n",
    "W = np.random.randn(2, 3)\n",
    "B = np.random.randn(3)\n",
    "\n",
    "print(X.shape, W.shape, B.shape, '\\n', '-'*30)\n",
    "Y = np.dot(X, W) + B\n",
    "\n",
    "print(Y, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1031b6",
   "metadata": {},
   "source": [
    "* 계산 그래프로 그려보면 다음과 같다.<br/>\n",
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2F3e4957c3-2774-40f4-a188-a635cae3c80c%2Fimage.png\" align=\"left\" height=\"300px\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f416d0",
   "metadata": {},
   "source": [
    "* 지금까지의 계산 그래프는 노드 사이에 스칼라값이 흘렀지만, 이 예에서는 <span style='color:blue'>행렬</span>이 흐르고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4981f32",
   "metadata": {},
   "source": [
    "* 이제 역전파에 대해 생각해보자.<br/>\n",
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2F15b1ed85-ef9f-4748-bc0d-c68cad4365a8%2Fimage.png\" align=\"left\" height=\"500px\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb77cd0",
   "metadata": {},
   "source": [
    "### 5.6.2 배치용 Affine 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093201f",
   "metadata": {},
   "source": [
    "* 지금까지 설명한 Affine 계층은 입력데이터로 $\\mathbf X$ 하나만을 고려한 것이었다.\n",
    "* 이번 절에서는 데이터 N개를 묶어 순전파 하는 경우, 즉 <span style='color:blue'>배치용 Affine 계층</span>을 생각해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d90932",
   "metadata": {},
   "source": [
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2Fd6d7dc51-82bb-4fac-aa1b-70831aec499c%2Fimage.png\" align=\"left\" height=\"500px\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a359bef",
   "metadata": {},
   "source": [
    "* 기존과 다른 부분은 입력인 $\\mathbf X$의 형상이 (N, 2)가 된 것뿐이다.\n",
    "* 그 뒤로는 지금까지와 같이 계산 그래프의 순서를 따라 행렬 계산을 하게 된다.\n",
    "* 또, 역전파 때는 행렬의 형상에 주의하면 $\\partial{L}\\over\\partial{X}$과 $\\partial{L}\\over\\partial{W}$은 이전과 같이 도출할 수 있다.\n",
    "* 편향을 더할 때도 주의해야 한다.\n",
    "* 순전파 때의 편향 덧셈은 $X\\cdot W$에 대한 편향이 각 데이터에 더해진다.\n",
    "* 예를들어 N = 2인 경우, 편향은 그 두 데이터 각각에 더해진다. 구체적인 예를 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febc9f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0]\n",
      " [10 10 10]] \n",
      " -------------------- \n",
      " [[ 1  2  3]\n",
      " [11 12 13]]\n"
     ]
    }
   ],
   "source": [
    "X_dot_W = np.array([[0, 0, 0], [10, 10, 10]])\n",
    "B = np.array([1, 2, 3])\n",
    "\n",
    "print(X_dot_W, '\\n', '-'*20, '\\n', X_dot_W + B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbdc34c",
   "metadata": {},
   "source": [
    "* 순전파의 편향 덧셈은 각각의 데이터에 더해진다.\n",
    "* 그래서 역전파 때는 각 데이터의 역전파 값이 편향의 원소에 모여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "878654b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]] \n",
      " -------------------- \n",
      " [5 7 9]\n"
     ]
    }
   ],
   "source": [
    "dY = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "dB = np.sum(dY, axis=0)\n",
    "\n",
    "print(dY, '\\n', '-'*20, '\\n', dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7826c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.dB = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW =  np.dot(self.x.T, dout)\n",
    "        self.dB = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734efd99",
   "metadata": {},
   "source": [
    "### 5.6.3 Softmax-with-Loss 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186568c1",
   "metadata": {},
   "source": [
    "* 마지막으로 출력층에서 사용하는 softmax 함수에 대해 알아보자.\n",
    "* softmax 함수는 입력 값을 정규화하여 출력한다.\n",
    "* softmax 계층을 구현 할 때, 손실함수인 교차 엔트로피 오차도 포함하여 <span style='color:blue'>'softmax_with_loss 계층'</span>으로 구현해보자.\n",
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2Facbf3ae5-e7cf-420e-aaa2-98346d01cd9f%2Fimage.png\" align=\"left\" height=\"500px\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7e1ba",
   "metadata": {},
   "source": [
    "* 보다시피 softmax_with_loss 계층은 다소 복잡하다. 위의 계산 그래프를 아래와 같이 간소화 할 수 있다.\n",
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2F823d0de6-e8e1-40c2-8e51-29a2ebc76b4c%2Fimage.png\" align=\"left\" height=\"500px\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34de2775",
   "metadata": {},
   "source": [
    "* 위의 계산 그래프에서 softmax함수는 'Softmax'계층으로, 교차 엔트로피 오차는 'Cross Entropy Error'계층으로 표기했다.\n",
    "* Softmax 계층은 입력 $(a_{1}, a_{2}, a_{3})$를 정규화하여 $(y_{1}, y_{2}, y_{3})$를 출력한다.\n",
    "* Cross Entropy Error 계층은 Softmax의 출력 $(y_{1}, y_{2}, y_{3})$와 정답 레이블 $(t_{1}, t_{2}, t_{3})$를 받고, 이 데이터들로부터 손실 $L$을 출력한다.\n",
    "* 위 계산 그래프에서 주목할 것은 역전파의 결과이다.\n",
    "* Softmax 계층의 역전파는 $({y_{1} - t_{1}}, {y_{2} - t_{2}}, {y_{3} - t_{3}})$ 이라는 말끔한 결과를 내놓고 있다.\n",
    "* 신경망의 역전파에서는 오차(출력과 정답 레이블의 차이)가 앞 계층에 전해진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52c1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3179fac",
   "metadata": {},
   "source": [
    "## 5.7 오차역전파법 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99b314",
   "metadata": {},
   "source": [
    "### 5.7.1 신경망 학습의 전체 그림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d75c71",
   "metadata": {},
   "source": [
    "#### <span style='background-color:yellow'>전제</span> <br/>\n",
    "신경망에는 적응 가능한 가중치와 편향이 있고, 이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 '학습'이라고 한다.<br/>신경망 학습은 다음과 같이 4단계로 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d668494",
   "metadata": {},
   "source": [
    "#### <span style='background-color:yellow'>1단계 - 미니배치</span> <br/>\n",
    "훈련데이터 중 일부를 무작위로 가져온다. 이렇게 선별한 배치를 <span style='color:blue'>미니배치</span>라 하며, <br/>그 미니배치의 손실 함수 값을 줄이는 것이 목표이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d1d28e",
   "metadata": {},
   "source": [
    "#### <span style='background-color:yellow'>2단계 - 기울기 산출</span> <br/>\n",
    "미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다.<br/>\n",
    "기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a669e8",
   "metadata": {},
   "source": [
    "#### <span style='background-color:yellow'>3단계 - 매개변수 갱신</span> <br/>\n",
    "가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6b66b5",
   "metadata": {},
   "source": [
    "#### <span style='background-color:yellow'>4단계 - 반복</span> <br/>\n",
    "1~3단계를 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ff7984",
   "metadata": {},
   "source": [
    "* 지금까지 설명한 오차역전파법이 등장하는 단계는 두 번째인 기울기 산출이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a138c998",
   "metadata": {},
   "source": [
    "### 5.7.2 오차역전파법을 적용한 신경망 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080698e",
   "metadata": {},
   "source": [
    "* 신경망을 구현하기 전에, 이 클래스의 인스턴스 변수와 메서드를 정리한 표를 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ea2a5",
   "metadata": {},
   "source": [
    "<img src=\"https://velog.velcdn.com/images%2Flilpark%2Fpost%2Fe59169aa-7883-446e-890b-16bc518b9b4f%2Fimage.png\" align=\"left\" height=\"700px\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42fcf6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def step_function(x):\n",
    "    return np.array(x > 0, dtype=np.int)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))    \n",
    "\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
    "    \n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def relu_grad(x):\n",
    "    grad = np.zeros(x)\n",
    "    grad[x>=0] = 1\n",
    "    return grad\n",
    "    \n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "\n",
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)\n",
    "\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "\n",
    "def softmax_loss(X, t):\n",
    "    y = softmax(X)\n",
    "    return cross_entropy_error(y, t)\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = sigmoid(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 가중치와 편향 매개변수의 미분\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 텐서 대응\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
    "        return dx\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩 형태일 때\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c860086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1:\n",
    "            t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads={}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        # 순전파\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        # 역전파\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['W2'] = self.layers['Affine2'].dW\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049fc0b7",
   "metadata": {},
   "source": [
    "### 5.7.3 오차역전파법으로 구한 기울기 검증하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39f3cad",
   "metadata": {},
   "source": [
    "* 수치미분은 오차역전파법에 비해 느리다. 하지만 오차역전파법을 정확히 구현했는지 확인하기 위해 필요하다.\n",
    "* 수치미분의 이점은 구현하기 쉽다는 것이다. 하지만 오차역전파법은 구현하기 복잡해서 종종 실수를 하곤 한다.\n",
    "* 그래서 수치미분의 결과와 오차역전파법의 결과를 비교하여 오차역전파법을 제대로 구현했는지 검증하곤 한다.\n",
    "* 이처럼 두 방식으로 구한 기울기가 일치함을 확인하는 작업을 <span style=\"color:blue\">기울기 확인</span>이라고 한다\n",
    "* 기울기 확인은 다음과 같이 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ad7bc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:5.894402783091998e-10\n",
      "b1:3.389520343303944e-09\n",
      "W2:6.170298644618993e-09\n",
      "b2:1.4022778820621528e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mnist import load_mnist\n",
    "from collections import OrderedDict\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 각 가중치의 차이의 절댓값을 구한 후, 그 절댓값들의 평균을 낸다\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(key + \":\" + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa5259f",
   "metadata": {},
   "source": [
    "* 이 결과는 수치미분과 오차역전파법으로 구한 기울기의 차이가 매우 작다고 말해준다.\n",
    "* 이로써 오차역전파법으로 구한 기울기도 올바름이 드러나면서 실수없이 구현했다는 믿음이 커진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7754d3",
   "metadata": {},
   "source": [
    "### 5.7.4 오차역전파법을 사용한 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b1e2dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12058333333333333 0.1233\n",
      "0.9007833333333334 0.9028\n",
      "0.9218666666666666 0.9245\n",
      "0.9353 0.9354\n",
      "0.9443 0.9431\n",
      "0.95285 0.9498\n",
      "0.9567333333333333 0.9532\n",
      "0.9610833333333333 0.9581\n",
      "0.9647 0.9604\n",
      "0.9684333333333334 0.9627\n",
      "0.9692833333333334 0.9654\n",
      "0.9721166666666666 0.9664\n",
      "0.9732666666666666 0.9658\n",
      "0.97585 0.9683\n",
      "0.9775666666666667 0.9675\n",
      "0.9790833333333333 0.9706\n",
      "0.9802666666666666 0.9711\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 오차역전파법으로 기울기를 구한다.\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6cae87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64de2fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
